---
layout: default
title: "Using LLM Assisted IDEs"
date: 2025-01-27
categories: ai
---

## Introduction

I have been using two different IDEs that have LLMs incorporated on and off for the last year and wanted to talk about my impressions at this point in time. I just wanted to write down my current impressions. I'll note that this is early January 2025 and the landscape seems to progress really quickly! 

## Copilot Inline Suggestions

My first introduction to AI assisted IDEs was getting a GitHub Copilot license through work. At the time we were only able to use tools that were not in preview or beta for **reasons**, so we couldn't immediately get access to other tools that were on the horizon such as Copilot Chat.

Copilot as an autocomplete was fine. That's really all I'd say. It would be a good tool to occasionally fill out the rest of a function, but it only felt like it was good for very specific use cases. You would want to put in comments ahead of time to prompt a direction for the LLM to generate (which then you'd have to delete afterwards), you'd want to put in full function definitions with typings for Python functions in order to get the best auto complete situation, and anytime you'd try and edit something in the middle of the line instead of only at the end made the autocomplete seem to completely fail over. Also it seemed to do poorly with terraform logic.

Looking back on that time I feel like it's telling of what I think the capabilities of the first versions of Copilot were when I keep call it autocomplete rather than things like `code completion`. I think I also didn't really find it useful enough for me to really look into other ways to make the process better. I think the assumption that I made was that any additional learning that I needed to do on how to best "prompt" Copilot would require more time than the efficiency gains it **could** have provided.

## Copilot Chat
### Pros
Once Copilot Chat moved out of beta / preview and released to the public, I started using Copilot Chat in VSCode. It was a game changer compared to the inline suggestions. I found three use cases especially helpful:

1. Describing a function in depth and letting the Agent build
2. Creating prototypes of a new stack quickly
3. Troubleshooting from a stack trace error and the source code as context

Giving step by step instructions of what I expect the function to do but I may not know the syntax for was a great use case for Copilot. In one case I needed to interact with AWS where one API call requested that a resource be cerated, and after an unknown amount of time the service will be created. I used Copilot to describe that I wanted to request for status of the resource creation to occur with an exponential back off. Copilot was immediately able to generate a working code snippet that I was able to implement and tweak, especially since Typescript was not a familiar language to me at the time.

Protoypes of a new stack is a great use case for the Chat with an expanding context window. I liked to start with describing the Makefile that I would use in dev purposes to give almost a defacto skeleton of what the "structure" should be for the protoype project.

Inputting a stack trace error with the source code as context, I don't even need to say "fix it" and the agent would try and find a solution for the error encountered. It may only work like 60% of the time, but as a first step it's a great option to just try and find an easy win by passing in an unknown error into the LLM.

### Cons
I still found certain aspects of Copilot Chat less than ideal though.

- It felt like I was still copying and pasting a lot between windows in VSCode. Copy from terminal directly into the chat, or copy from chat back into the source code, etc.
- I know it's not ONLY limited to a single file as context, but Copilot Chat felt like it was not particularly aware of file contents in adjacent files.
- Certain actions like "apply to code" felt **SO** slow. It was usually faster for me to just copy and paste the code myself.
- It's very verbose for any text generated.

## Windsurf
I started using the Windsurf IDE after reading about it on the Pragmatic Engineer blog about IDEs that are focused on LLMs. I wanted to use it for Advent of Code to see if I could use some other programming languages that I don't get to use as often at work anymore. I was in for a surprise on how good it was to create whole projects from scratch. Not only does it create a whole project as intended, but I did not need to go through step wise creation like I would otherwise with Copilot. The agent that's included went through each file stepwise for me and all I would need to do is review the files created. Also Windsurf was great at taking **multiple** files as context, or at least figured out on its own when it needed to take multiple files as context. One example is this very blog here. In one case there was a deprecation message that a certain feature would need to change how links are handled. Not only did I have Windsurf fix the problem for a single file (which I then reviewed in source code and by checking the files locally), I then had the `Cascade Agent` fix all of the other links in 10+ other files by just telling it to make the changes in other files. It analyzed the rest of the workspace, found all of the files that needed changing, and changed them!

I found that Sonnet model seems to have better `code generation` than the 4o model, but I don't really have any good examples of how it's better other than it "feels" better.

Finally the Cascade agent is simply much better at being able to interact with the IDE than Copilot Chat. Changes are applied quicker, it's able to run simple commands from within the agent, and even use the output for context for follow-on prompts. I'm impressed with how helpful the tool is with speeding up development.

Overall I'm very impressed, to the point that I actually pay for a monthly license even if I don't have access for it at work (yet).
